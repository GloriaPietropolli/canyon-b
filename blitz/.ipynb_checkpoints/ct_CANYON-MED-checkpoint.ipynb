{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CANYON-MED \n",
    "Implementation following the instruction of the article *'A Regional Neural Network Approach to  estimate Water-COlumn Nutrient COncentrations and Carbonate System Variables in the Mediterranean Sea: CANYON-MED'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from blitz.modules import BayesianLinear\n",
    "from IPython import display\n",
    "from torchvision import datasets, transforms\n",
    "from res.plot_lib import plot_data, plot_model, set_default\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=4/3\n",
    "a=1.7159\n",
    "def mysigmoid(x):\n",
    "    return A*torch.sigmoid(x*a/2) #A*(np.exp(a*x) -1)/(np.exp(a*x)+1)\n",
    "\n",
    "class MySigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return mysigmoid(x)\n",
    "        \n",
    "activation_function = MySigmoid() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#presgrid=pd.read_excel(\"../dataset/CY_doy_pres_limit.ods\")\n",
    "data=pd.read_csv(\"../dataset/data_CT.csv\")\n",
    "mont_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "\n",
    "dataset=data[data.categ=='training']          \n",
    "validation=data[data.categ=='validation']\n",
    "\n",
    "out_d=dataset['tcarbn'].to_numpy()\n",
    "in_d=dataset[['date','date', 'date','latitude', 'longitude', 'pres', 'temp', 'doxy', 'psal']].to_numpy()\n",
    "\n",
    "out_v=validation['tcarbn'].to_numpy()\n",
    "in_v=validation[['date','date', 'date', 'latitude', 'longitude', 'pres', 'temp', 'doxy', 'psal']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixd(dataset):\n",
    "    for i in range(len(dataset[:,0])):\n",
    "        dataset[i,0] = int(dataset[i,0][7:11])\n",
    "        dataset[i,1] = mont_dict[dataset[i,1][3:6]]\n",
    "        dataset[i,2] = int(dataset[i,2][0:2])\n",
    "\n",
    "fixd(in_d)\n",
    "fixd(in_v)\n",
    "in_d=in_d.astype('float64')\n",
    "in_v=in_v.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(in_d)\n",
    "target = torch.from_numpy(out_d)\n",
    "data=data.float()\n",
    "target=target.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(data):\n",
    "    data[:,3]=data[:,3]/90                                                           #latitude [-90,90]/90\n",
    "    data[:,5]=(data[:,5]/20000) + (1 / ((1+np.exp(-(data[:,5])/300))**3))            #pressure\n",
    "    for i in range(len(data[:,0])):\n",
    "        day=data[i,2].item()\n",
    "        month=data[i,1]*30\n",
    "        month=month.item()\n",
    "        time=day+month\n",
    "        data[i,1]=np.cos(time*2*np.pi/365)*100\n",
    "        data[i,2]=np.sin(time*2*np.pi/365)*100\n",
    "        if data[i,4]>180:\n",
    "            data[i,4]=data[i,4]-360                                                  #longitude\n",
    "    return data\n",
    "\n",
    "data=prep_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_fun_d(data):\n",
    "    mean=[ data[:,i].mean() for i in range(data.size()[1]) ]\n",
    "    std =[ data[:,i].std() for i in range(data.size()[1]) ]\n",
    "    for i in range(data.size()[1]):\n",
    "        data[:,i]=2/3*(data[:,i]-mean[i])/std[i] \n",
    "    return data, mean, std\n",
    "\n",
    "def norm_fun_t(target):\n",
    "    mean=target.mean()\n",
    "    std=target.std()\n",
    "    #target=2/3*(target-mean)/std\n",
    "    return mean, std #target, mean, std\n",
    "\n",
    "data, mean_data, std_data=norm_fun_d(data)\n",
    "#mean_ct, std_ct =norm_fun_t(target)\n",
    "#target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=9 #input number\n",
    "best_topo_all=[[i,31,23,1],[i,20,8,1],[i,18,13,1],[i,35,21,1],[i,35,9,1],[i,36,21,1],[i,39,26,1],[i,44,27,1],[i,47,21,1],[i,47,29,1]]\n",
    "\n",
    "def top_select(best_topo_all, n):\n",
    "    best_topo=best_topo_all[0:n]\n",
    "    return best_topo  \n",
    "\n",
    "best_topo=top_select(best_topo_all,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Bayesian(nn.Module):\n",
    "    def __init__(self, top):\n",
    "        input_size, n_hidden1, n_hidden2, output_size = best_topo[top]\n",
    "        super( MLP_Bayesian , self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.network = nn.Sequential(\n",
    "            BayesianLinear(input_size, n_hidden1), #nn.Linear(input_size, n_hidden1), #\n",
    "            nn.SELU(),  # activation_function, # funzione bene con nn.ReLU(), ELU(),\n",
    "            BayesianLinear(n_hidden1, n_hidden2), #nn.Linear(n_hidden1, n_hidden2), #\n",
    "            nn.SELU(), #activation_function, #\n",
    "            BayesianLinear(n_hidden2, output_size), #nn.Linear(n_hidden2, output_size), #\n",
    "            nn.SELU()  #activation_function #\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "losses= [] \n",
    "def train(model, ep):\n",
    "    \n",
    "    for t in range(ep):\n",
    "        \n",
    "        output = model(data)\n",
    "        criterion=torch.nn.L1Loss()                                        #criterion=torch.nn.L1Loss()\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        print(f\"[MODEL]: {top+1}, [EPOCH]: {t}, [LOSS]: {loss.item():.6f}\")\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=list()\n",
    "models_loss=[]\n",
    "epoch=1000\n",
    "for top in range(len(best_topo)):\n",
    "    model_mlp=MLP_Bayesian(top)\n",
    "    models.append(model_mlp)\n",
    "    optimizer = optim.(model_mlp.parameters(), lr=0.01)# , momentum=0.5)\n",
    "    train(model_mlp, epoch)\n",
    "    \n",
    "model=models[0]\n",
    "result=model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sol(sol,prev): \n",
    "    plt.scatter(sol.detach().numpy() ,prev.detach().numpy())\n",
    "    plt.plot(sol, sol)\n",
    "    plt.xlabel('C_t in situ')\n",
    "    plt.ylabel('C_t CANYON-MED')\n",
    "    \n",
    "plot_sol(target, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(ep, losses):\n",
    "    ep_vect=[i for i in range(ep)]\n",
    "    plt.plot(ep_vect, losses, label= 'loss during epochs')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    \n",
    "error_plot(epoch, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR COMBINATION OF THE BEST 10 OUTPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def ct_result(my_input):\n",
    "    outputs=[]\n",
    "    for top in range(len(best_topo)):\n",
    "        my_model=models[top]\n",
    "        my_output=my_model(my_input)\n",
    "        outputs.append(my_output)\n",
    "    out=sum(outputs)/len(outputs)\n",
    "    return out\n",
    "\n",
    "#out=ct_result(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
