{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CANYON-MED \n",
    "Implementation following the instruction of the article *'A Regional Neural Network Approach to  estimate Water-COlumn Nutrient COncentrations and Carbonate System Variables in the Mediterranean Sea: CANYON-MED'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from blitz.modules import BayesianLinear\n",
    "from IPython import display\n",
    "from torchvision import datasets, transforms\n",
    "from res.plot_lib import plot_data, plot_model, set_default\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toYearFraction(date):\n",
    "    def sinceEpoch(date): # returns seconds since epoch\n",
    "        return time.mktime(date.timetuple())\n",
    "    s = sinceEpoch\n",
    "\n",
    "    year = date.year\n",
    "    startOfThisYear = dt(year=year, month=1, day=1)\n",
    "    startOfNextYear = dt(year=year+1, month=1, day=1)\n",
    "\n",
    "    yearElapsed = s(date) - s(startOfThisYear)\n",
    "    yearDuration = s(startOfNextYear) - s(startOfThisYear)\n",
    "    fraction = yearElapsed/yearDuration\n",
    "\n",
    "    return date.year + fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=4/3\n",
    "a=1.7159\n",
    "def mysigmoid(x):\n",
    "    return A*torch.sigmoid(x*a/2) \n",
    "\n",
    "class MySigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,x):\n",
    "        return mysigmoid(x)\n",
    "        \n",
    "activation_function = MySigmoid() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../dataset/data_CT.csv\")\n",
    "mont_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "\n",
    "dataset=data[data.categ=='training']          \n",
    "validation=data[data.categ=='validation']\n",
    "\n",
    "out_d=dataset['tcarbn'].to_numpy()\n",
    "in_d=dataset[['date','latitude', 'longitude', 'pres', 'temp', 'doxy', 'psal']].to_numpy()\n",
    "\n",
    "out_v=validation['tcarbn'].to_numpy()\n",
    "in_v=validation[['date', 'latitude', 'longitude', 'pres', 'temp', 'doxy', 'psal']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixd(dataset):\n",
    "    for i in range(len(dataset[:,0])):\n",
    "        dataset[i,0] = dt(int(dataset[i,0][7:11]), mont_dict[dataset[i,0][3:6]] , int(dataset[i,0][0:2]))\n",
    "        dataset[i,0] = toYearFraction(dataset[i,0])\n",
    "\n",
    "fixd(in_d)\n",
    "fixd(in_v)\n",
    "in_d=in_d.astype('float64')\n",
    "in_v=in_v.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.from_numpy(in_d)\n",
    "target = torch.from_numpy(out_d)\n",
    "data=data.float()\n",
    "target=target.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(data):\n",
    "    for i in range(len(data[:,0])):\n",
    "        if data[i,4]>180:\n",
    "            data[i,4]=data[i,4]-360                                                  #longitude\n",
    "    data[:,3]=data[:,3]/90                                                           #latitude [-90,90]/90\n",
    "    data[:,5]=(data[:,5]/20000) + (1 / ((1+np.exp(-(data[:,5])/300))**3))            #pressure\n",
    "    return data\n",
    "\n",
    "data=prep_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_fun_d(data):\n",
    "    mean=[ data[:,i].mean() for i in range(data.size()[1]) ]\n",
    "    std =[ data[:,i].std() for i in range(data.size()[1]) ]\n",
    "    for i in range(data.size()[1]):\n",
    "        data[:,i]=2/3*(data[:,i]-mean[i])/std[i] \n",
    "    return data, mean, std\n",
    "\n",
    "data, mean_data, std_data=norm_fun_d(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=7 #input number\n",
    "best_topo_all=[[i,31,23,1],[i,20,8,1],[i,18,13,1],[i,35,21,1],[i,35,9,1],[i,36,21,1],[i,39,26,1],[i,44,27,1],[i,47,21,1],[i,47,29,1]]\n",
    "\n",
    "def top_select(best_topo_all, n):\n",
    "    best_topo=best_topo_all[0:n]\n",
    "    return best_topo  \n",
    "\n",
    "best_topo=top_select(best_topo_all,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Bayesian(nn.Module):\n",
    "    def __init__(self, top):\n",
    "        input_size, n_hidden1, n_hidden2, output_size = best_topo[top]\n",
    "        super( MLP_Bayesian , self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.network = nn.Sequential(\n",
    "            BayesianLinear(input_size, n_hidden1), #nn.Linear(input_size, n_hidden1), #\n",
    "            activation_function, #nn.SELU(), #nn.Sigmoid(),  #funzione bene con nn.ReLU(), ELU(),\n",
    "            BayesianLinear(n_hidden1, n_hidden2), #nn.Linear(n_hidden1, n_hidden2), #\n",
    "            activation_function, #nn.SELU(), #nn.Sigmoid(), \n",
    "            BayesianLinear(n_hidden2, output_size), #nn.Linear(n_hidden2, output_size), #\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "losses= [] \n",
    "def train(model, ep):\n",
    "    \n",
    "    for t in range(ep):\n",
    "        \n",
    "        output = model(data)\n",
    "        criterion=torch.nn.L1Loss()                                        #criterion=torch.nn.L1Loss()\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        print(f\"[MODEL]: {top+1}, [EPOCH]: {t}, [LOSS]: {loss.item():.6f}\")\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-830bb73be48e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# momentum=0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7e6738c1fdbc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, ep)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/blitz/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/blitz/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models=list()\n",
    "models_loss=[]\n",
    "epoch=500\n",
    "for top in range(len(best_topo)):\n",
    "    model_mlp=MLP_Bayesian(top)\n",
    "    models.append(model_mlp)\n",
    "    optimizer = optim.Adam(model_mlp.parameters(), lr=0.005)# momentum=0.5)\n",
    "    train(model_mlp, epoch)\n",
    "\n",
    "model=models[0]\n",
    "result=model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sol(sol,prev): \n",
    "    plt.scatter(sol.detach().numpy() ,prev.detach().numpy())\n",
    "    plt.plot(sol, sol)\n",
    "    plt.xlabel('C_t in situ')\n",
    "    plt.ylabel('C_t CANYON-MED')\n",
    "    \n",
    "plot_sol(target, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(ep, losses):\n",
    "    ep_vect=[i for i in range(ep)]\n",
    "    plt.plot(ep_vect, losses, label= 'loss during epochs')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    \n",
    "error_plot(epoch, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR COMBINATION OF THE BEST 10 OUTPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ct_result(my_input):\n",
    "    outputs=[]\n",
    "    for top in range(len(best_topo)):\n",
    "        my_model=models[top]\n",
    "        my_output=my_model(my_input)\n",
    "        outputs.append(my_output)\n",
    "    out=sum(outputs)/len(outputs)\n",
    "    return out\n",
    "\n",
    "#out=ct_result(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
